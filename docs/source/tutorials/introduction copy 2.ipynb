{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7b5e13a-c059-441d-8d4f-fff080d52054",
   "metadata": {},
   "source": [
    "# Kernels and hyperparameters\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c18ef717",
   "metadata": {},
   "source": [
    "This tutorial is an introduction to the syntax used by the optimizer, as well as the principles of Bayesian optimization in general.\n",
    "\n",
    "We'll start by minimizing Booth's function, which looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22438de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import bloptools\n",
    "\n",
    "x1 = x2 = np.linspace(-10, 10, 256)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "\n",
    "plt.pcolormesh(x1, x2, bloptools.experiments.tests.himmelblau(X1, X2), norm=mpl.colors.LogNorm(), shading=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecef8da5",
   "metadata": {},
   "source": [
    "There are several things that our agent will need. The first ingredient is some degrees of freedom (these are always `ophyd` devices) which the agent will move around to different inputs within each DOF's bounds (the second ingredient). We define these here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c870567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bloptools\n",
    "\n",
    "dofs = bloptools.experiments.tests.get_dummy_dofs(2)\n",
    "bounds = [(-10, 10), (-10, 10)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a88c7bd",
   "metadata": {},
   "source": [
    "The agent automatically samples at different inputs, but we often need some post-processing after data collection. In this case, we need to give the agent a way to compute Himmelblau's function. We accomplish this with a digestion function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bfcf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digestion(db, uid):\n",
    "\n",
    "    table = db[uid].table()\n",
    "    products = {\"himmelblau\": []}\n",
    "\n",
    "    for index, entry in table.iterrows():\n",
    "\n",
    "        products[\"himmelblau\"].append(bloptools.experiments.tests.himmelblau(entry.x1, entry.x2))\n",
    "\n",
    "    return products"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dad64303",
   "metadata": {},
   "source": [
    "The next ingredient is a task, which gives the agent something to do. We want it to minimize Himmelblau's function, so we make a task that will try to minimize the output of the digestion function called \"himmelblau\". We also include a transform function, which will make it easier to regress over the outputs of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloptools.tasks import Task\n",
    "\n",
    "task = Task(key=\"himmelblau\", kind=\"min\", transform=lambda x: np.log(1 + 1e-2 * x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d3d91c3",
   "metadata": {},
   "source": [
    "Combining all of these with a databroker instance, we can make an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a829f-a390-40dc-9d5b-ae75702e119e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -i ../../../examples/prepare_bluesky.py # prepare the bluesky environment\n",
    "\n",
    "boa = bloptools.bayesian.Agent(\n",
    "                                dofs=dofs, # things which we move around\n",
    "                                bounds=bounds, # where we're allowed to move them\n",
    "                                tasks=task, # tasks for the optimizer\n",
    "                                digestion=digestion, # how to process the acquisition into task data\n",
    "                                db=db, # a databroker instance\n",
    "                                )\n",
    "\n",
    "RE(boa.initialize(init_scheme='quasi-random', n_init=16))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8f2da43",
   "metadata": {},
   "source": [
    "We initialized the GP with the \"quasi-random\" strategy, as it doesn't require any prior data. We can view the state of the optimizer's posterior of the tasks over the input parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c3c01-f91d-4a25-9b8d-eba5fa964504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boa.plot_tasks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4274930c",
   "metadata": {},
   "source": [
    "We can also the agent's posterior about the probability of goodness over the parameters:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2eb855c",
   "metadata": {},
   "source": [
    "We want to learn a bit more, so we can ask the agent where to sample based off of some strategy. Here we use the \"esti\" strategy, which maximizes the expected sum of tasks improvement.\n",
    "\n",
    "We can ask the agent to \"route\" them using ``ortools``, so that we can sample them more quickly if it requires us to e.g. move motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_to_sample = boa.ask(strategy='esti', n=16, optimize=True, route=True)\n",
    "plt.scatter(*X_to_sample.T)\n",
    "plt.plot(*X_to_sample.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "296d9fd2",
   "metadata": {},
   "source": [
    "Let's tell the agent to learn a bit more (it will direct itself):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e74651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RE(boa.learn(strategy='esti', n_iter=1, n_per_iter=4))\n",
    "boa.plot_tasks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aeab7a9b",
   "metadata": {},
   "source": [
    "The agent has updated its model of the tasks, including refitting the hyperparameters. Continuing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b39b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RE(boa.learn(strategy='esti', n_iter=4, n_per_iter=4))\n",
    "boa.plot_tasks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e955233f",
   "metadata": {},
   "source": [
    "Eventually, we reach a point of saturation where no more improvement takes place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e4fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RE(boa.learn(strategy='esti', n_iter=4, n_per_iter=4))\n",
    "boa.plot_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad4b1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9aced674e98d511b4f654e147532c84d38dc986fe042b1e92785fb9d8df41f75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
