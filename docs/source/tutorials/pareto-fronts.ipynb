{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Multiobjective optimization with Pareto front mapping\n",
    "\n",
    "One way to do multiobjective optimization is with Pareto optimization, which explores the set of Pareto-efficient points. A point is Pareto-efficient if there are no other valid points that are better at every objective: it shows the \"trade-off\" between several objectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from bluesky.callbacks import best_effort\n",
    "from bluesky.callbacks.tiled_writer import TiledWriter\n",
    "from bluesky.run_engine import RunEngine\n",
    "from ophyd.utils import make_dir_tree  # Constants\n",
    "from tiled.client import from_uri\n",
    "from tiled.server import SimpleTiledServer\n",
    "\n",
    "DEFAULT_ROOT_DIR = \"/tmp/sirepo-bluesky-data\"\n",
    "\n",
    "tiled_server = SimpleTiledServer()\n",
    "tiled_client = from_uri(tiled_server.uri)\n",
    "tiled_writer = TiledWriter(tiled_client)\n",
    "\n",
    "\n",
    "def setup_re_env(db_type=\"default\", root_dir=\"/default/path\"):\n",
    "    RE = RunEngine({})\n",
    "    bec = best_effort.BestEffortCallback()\n",
    "    RE.subscribe(bec)\n",
    "    RE.subscribe(tiled_writer)\n",
    "    _ = make_dir_tree(datetime.datetime.now().year, base_path=root_dir)\n",
    "    return {'RE': RE, 'tiled': tiled_client, 'bec': bec}\n",
    "\n",
    "\n",
    "env = setup_re_env(db_type=\"temp\", root_dir=DEFAULT_ROOT_DIR)\n",
    "globals().update(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from blop import DOF, Agent, Objective\n",
    "\n",
    "\n",
    "def digestion(df):\n",
    "    for index, entry in df.iterrows():\n",
    "        x1, x2 = entry.x1, entry.x2\n",
    "\n",
    "        df.loc[index, \"f1\"] = (x1 - 2) ** 2 + (x2 - 1) + 2\n",
    "        df.loc[index, \"f2\"] = 9 * x1 - (x2 - 1) + 2\n",
    "        df.loc[index, \"c1\"] = x1**2 + x2**2\n",
    "        df.loc[index, \"c2\"] = x1 - 3 * x2 + 10\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "dofs = [\n",
    "    DOF(name=\"x1\", search_domain=(-20, 20)),\n",
    "    DOF(name=\"x2\", search_domain=(-20, 20)),\n",
    "]\n",
    "\n",
    "\n",
    "objectives = [\n",
    "    Objective(name=\"f1\", target=\"min\"),\n",
    "    Objective(name=\"f2\", target=\"min\"),\n",
    "    Objective(name=\"c1\", constraint=(-np.inf, 225)),\n",
    "    Objective(name=\"c2\", constraint=(-np.inf, 0)),\n",
    "]\n",
    "\n",
    "agent = Agent(\n",
    "    dofs=dofs,\n",
    "    objectives=objectives,\n",
    "    digestion=digestion,\n",
    "    tiled=tiled,\n",
    ")\n",
    "\n",
    "(uid,) = RE(agent.learn(\"qr\", n=64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "We can plot our fitness and constraint objectives to see their models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.plot_objectives()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "We can plot the Pareto front (the set of all Pareto-efficient points), which shows the trade-off between the two fitnesses. The points in blue comprise the Pareto front, while the points in red are either not Pareto efficient or are invalidated by one of the constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.plot_pareto_front()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "We can explore the Pareto front by choosing a random point on the Pareto front and computing the expected improvement in the hypervolume of all fitness objectives with respect to that point (called the \"reference point\"). All this is done automatically with the `qnehvi` acquisition function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is broken now but is fixed in the next PR\n",
    "# RE(agent.learn(\"qnehvi\", n=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiled_server.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pixi_Tiled_new",
   "language": "python",
   "name": "tiled-pixi-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
