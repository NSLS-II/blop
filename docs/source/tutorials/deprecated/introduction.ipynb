{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction (Himmelblau's function)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "[DEPRECATED] This tutorial will no longer work in Blop v1.0. See the Ax-Blop demo tutorial for a more up-to-date example.\n",
    "Let's use ``blop`` to minimize Himmelblau's function, which has four global minima:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Select the type of data storage system you would like to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import bluesky.plan_stubs as bps  # noqa F401\n",
    "import bluesky.plans as bp  # noqa F401\n",
    "import databroker  # type: ignore[import-untyped]\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from bluesky.callbacks import best_effort\n",
    "from bluesky.callbacks.tiled_writer import TiledWriter\n",
    "from bluesky.run_engine import RunEngine\n",
    "from databroker import Broker\n",
    "from ophyd.utils import make_dir_tree  # type: ignore[import-untyped]\n",
    "from tiled.client import from_uri  # type: ignore[import-untyped]\n",
    "from tiled.server import SimpleTiledServer\n",
    "\n",
    "from blop import DOF, Agent, Objective\n",
    "from blop.sim import HDF5Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiled_server = SimpleTiledServer()\n",
    "tiled_client = from_uri(tiled_server.uri)\n",
    "tiled_writer = TiledWriter(tiled_client)\n",
    "\n",
    "\n",
    "def setup_re_env(db_type=\"default\", root_dir=\"/default/path\", method=\"tiled\"):\n",
    "    RE = RunEngine({})\n",
    "    bec = best_effort.BestEffortCallback()\n",
    "    RE.subscribe(bec)\n",
    "    _ = make_dir_tree(datetime.now().year, base_path=root_dir)\n",
    "\n",
    "    if method.lower() == \"tiled\":\n",
    "        RE.subscribe(tiled_writer)\n",
    "        return {\"RE\": RE, \"db\": tiled_client, \"bec\": bec}\n",
    "\n",
    "    elif method.lower() == \"databroker\":\n",
    "        db = Broker.named(db_type)\n",
    "        db.reg.register_handler(\"HDF5\", HDF5Handler, overwrite=True)\n",
    "        try:\n",
    "            databroker.assets.utils.install_sentinels(db.reg.config, version=1)\n",
    "        except Exception:\n",
    "            pass\n",
    "        RE.subscribe(db.insert)\n",
    "        return {\"RE\": RE, \"db\": db, \"bec\": bec, }\n",
    "    else:\n",
    "        raise ValueError(\"The method for data storage used is not supported\")\n",
    "\n",
    "\n",
    "def register_handlers(db, handlers):\n",
    "    for handler_spec, handler_class in handlers.items():\n",
    "        db.reg.register_handler(handler_spec, handler_class, overwrite=True)\n",
    "\n",
    "\n",
    "env = setup_re_env(db_type=\"temp\", root_dir=\"/tmp/blop/sim\", method=\"databroker\")\n",
    "globals().update(env)\n",
    "bec.disable_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "from blop.utils import functions\n",
    "\n",
    "x1 = x2 = np.linspace(-6, 6, 256)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "\n",
    "F = functions.himmelblau(X1, X2)\n",
    "\n",
    "plt.pcolormesh(x1, x2, F, norm=mpl.colors.LogNorm(vmin=1e-1, vmax=1e3), cmap=\"magma_r\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "There are several things that our agent will need. The first ingredient is some degrees of freedom (these are always `ophyd` devices) which the agent will move around to different inputs within each DOF's bounds (the second ingredient). We define these here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dofs = [\n",
    "    DOF(name=\"x1\", search_domain=(-6, 6)),\n",
    "    DOF(name=\"x2\", search_domain=(-6, 6)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "We also need to give the agent something to do. We want our agent to look in the feedback for a variable called 'himmelblau', and try to minimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives = [Objective(name=\"himmelblau\", description=\"Himmeblau's function\", target=\"min\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "In our digestion function, we define our objective as a deterministic function of the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digestion(df):\n",
    "    df[\"himmelblau\"] = []\n",
    "    for (val_x1, val_x2) in zip(df.get(\"x1\"), df.get(\"x2\"), strict=False):\n",
    "        df[\"himmelblau\"].append(functions.himmelblau(val_x1, val_x2))\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "We then combine these ingredients into an agent, giving it an instance of ``databroker`` so that it can see the output of the plans it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    dofs=dofs,\n",
    "    objectives=objectives,\n",
    "    digestion=digestion,\n",
    "    db=db,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Without any data, we can't make any inferences about what the function looks like, and so we can't use any non-trivial acquisition functions. Let's start by quasi-randomly sampling the parameter space, and plotting our model of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(agent.learn(\"quasi-random\", n=36))\n",
    "agent.plot_objectives()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "To decide which points to sample, the agent needs an acquisition function. The available acquisition function are here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.all_acqfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Now we can start to learn intelligently. Using the shorthand acquisition functions shown above, we can see the output of a few different ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.plot_acquisition(acqf=\"qei\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "To decide where to go, the agent will find the inputs that maximize a given acquisition function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.ask(\"qei\", n=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "We can also ask the agent for multiple points to sample and it will jointly maximize the acquisition function over all sets of inputs, and find the most efficient route between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = agent.ask(\"qei\", n=8, route=True)\n",
    "agent.plot_acquisition(acqf=\"qei\")\n",
    "plt.scatter(res[\"points\"][\"x1\"], res[\"points\"][\"x2\"], marker=\"d\", facecolor=\"w\", edgecolor=\"k\")\n",
    "plt.plot(res[\"points\"][\"x1\"], res[\"points\"][\"x2\"], color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "All of this is automated inside the ``learn`` method, which will find a point (or points) to sample, sample them, and retrain the model and its hyperparameters with the new data. To do 4 learning iterations of 8 points each, we can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(agent.learn(\"qei\", n=4, iterations=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Our agent has found all the global minima of Himmelblau's function using Bayesian optimization, and we can ask it for the best point: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.plot_objectives()\n",
    "print(agent.best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
