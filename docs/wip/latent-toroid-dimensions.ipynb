{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7b5e13a-c059-441d-8d4f-fff080d52054",
   "metadata": {},
   "source": [
    "# Finding latent dimensions for the toroidal mirror \n",
    "\n",
    "It is common that beamline inputs are highly coupled, and so the effect of an input on the beam cannot be understood except in concert with the others. In this example, we show how our agent figures out latent dimensions, as well as the benefit of doing so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8a6989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from blop.utils import prepare_re_env\n",
    "\n",
    "%run -i $prepare_re_env.__file__ --db-type=temp\n",
    "%run -i ../../../examples/prepare_tes_shadow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a829f-a390-40dc-9d5b-ae75702e119e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import blop\n",
    "from blop.experiments.sirepo.tes import w8_digestion\n",
    "\n",
    "dofs = [\n",
    "    {\"device\": toroid.x_rot, \"limits\": (-0.001, 0.001), \"kind\": \"active\"},\n",
    "    {\"device\": toroid.offz, \"limits\": (-0.5, 0.5), \"kind\": \"active\"},\n",
    "]\n",
    "\n",
    "tasks = [{\"key\": \"flux\", \"kind\": \"maximize\", \"transform\": \"log\"}]\n",
    "\n",
    "agent = blop.bayesian.Agent(\n",
    "    dofs=dofs,\n",
    "    tasks=tasks,\n",
    "    dets=[w8],\n",
    "    digestion=w8_digestion,\n",
    "    db=db,\n",
    ")\n",
    "\n",
    "RE(agent.initialize(\"qr\", n_init=24))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6259a4f",
   "metadata": {},
   "source": [
    "We can see that the beam is only not cut off (i.e. it has a non-zero flux) in a diagonal strip, and that in fact this is really just a one-dimensional optimization problem in some diagonal dimension. Our agent has figured this out, with a transformation matrix that has a long coherence length in one dimension and a short coherence length orthogonal to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.tasks[0][\"model\"].covar_module.latent_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c3c01-f91d-4a25-9b8d-eba5fa964504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.plot_objectives()\n",
    "agent.plot_constraint()\n",
    "agent.plot_acquisition(strategy=[\"ei\", \"pi\", \"ucb\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
