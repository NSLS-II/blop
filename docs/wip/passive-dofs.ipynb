{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7b5e13a-c059-441d-8d4f-fff080d52054",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c18ef717",
   "metadata": {},
   "source": [
    "This tutorial is an introduction to the syntax used by the optimizer, as well as the principles of Bayesian optimization in general.\n",
    "\n",
    "We'll start by minimizing Himmelblau's function, which looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22438de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import bloptools\n",
    "\n",
    "x1 = x2 = np.linspace(-5.0, 5.0, 256)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "\n",
    "plt.pcolormesh(x1, x2, bloptools.experiments.tests.himmelblau(X1, X2), norm=mpl.colors.LogNorm(), shading=\"auto\")\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46924af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloptools.objects import TimeReadback\n",
    "\n",
    "tr = TimeReadback(name=\"timestamp\")\n",
    "\n",
    "tr.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecef8da5",
   "metadata": {},
   "source": [
    "There are several things that our agent will need. The first ingredient is some degrees of freedom (these are always `ophyd` devices) which the agent will move around to different inputs within each DOF's bounds (the second ingredient). We define these here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c870567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bloptools\n",
    "\n",
    "dofs = bloptools.objects.get_dummy_dofs(n=2)  # get a list of two DOFs\n",
    "bounds = [(-5.0, +5.0), (-5.0, +5.0)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a88c7bd",
   "metadata": {},
   "source": [
    "The agent automatically samples at different inputs, but we often need some post-processing after data collection. In this case, we need to give the agent a way to compute Himmelblau's function. We accomplish this with a digestion function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bfcf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bloptools\n",
    "\n",
    "dofs = bloptools.objects.get_dummy_dofs(n=2)  # get a list of two DOFs\n",
    "bounds = [(-5.0, +5.0), (-5.0, +5.0)]\n",
    "\n",
    "from bloptools.objects import TimeReadback\n",
    "\n",
    "tr = TimeReadback(name=\"timestamp\")\n",
    "\n",
    "tr.read()\n",
    "\n",
    "\n",
    "def digestion(db, uid):\n",
    "    table = db[uid].table()\n",
    "    products = pd.DataFrame()\n",
    "\n",
    "    for index, entry in table.iterrows():\n",
    "        products.loc[index, \"himmelblau\"] = bloptools.test_functions.himmelblau(entry.x1, entry.x2)\n",
    "\n",
    "    return products\n",
    "\n",
    "\n",
    "from bloptools.tasks import Task\n",
    "\n",
    "task = Task(key=\"himmelblau\", kind=\"min\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4532b087",
   "metadata": {},
   "source": [
    "The next ingredient is a task, which gives the agent something to do. We want it to minimize Himmelblau's function, so we make a task that will try to minimize the output of the digestion function called \"himmelblau\". We also include a transform function, which will make it easier to regress over the outputs of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloptools.tasks import Task\n",
    "\n",
    "task = Task(key=\"himmelblau\", kind=\"min\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d3d91c3",
   "metadata": {},
   "source": [
    "Combining all of these with a databroker instance, we can make an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a829f-a390-40dc-9d5b-ae75702e119e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -i ../../../examples/prepare_bluesky.py # prepare the bluesky environment\n",
    "\n",
    "boa = bloptools.bayesian.Agent(\n",
    "    dofs=dofs,\n",
    "    bounds=bounds,\n",
    "    passive_dims=[tr],\n",
    "    tasks=task,\n",
    "    digestion=digestion,\n",
    "    db=db,\n",
    ")\n",
    "\n",
    "RE(boa.initialize(init_scheme=\"quasi-random\", n_init=32))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8f2da43",
   "metadata": {},
   "source": [
    "We initialized the GP with the \"quasi-random\" strategy, as it doesn't require any prior data. We can view the state of the optimizer's posterior of the tasks over the input parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5818143a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.atleast_1d([]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c3c01-f91d-4a25-9b8d-eba5fa964504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boa.plot_tasks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2eb855c",
   "metadata": {},
   "source": [
    "We want to learn a bit more, so we can ask the agent where to sample based off of some strategy. Here we use the \"esti\" strategy, which maximizes the expected sum of tasks improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e74651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RE(boa.learn(strategy=\"esti\", n_iter=4))\n",
    "boa.plot_tasks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aeab7a9b",
   "metadata": {},
   "source": [
    "The agent has updated its model of the tasks, including refitting the hyperparameters. Continuing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b39b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RE(boa.learn(strategy=\"esti\", n_iter=16))\n",
    "boa.plot_tasks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e955233f",
   "metadata": {},
   "source": [
    "Eventually, we reach a point of saturation where no more improvement takes place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e4fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RE(boa.learn(strategy=\"esti\", n_iter=32))\n",
    "boa.plot_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad4b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "boa.tasks[0].regressor.covar_module.base_kernel.trans_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9abac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9aced674e98d511b4f654e147532c84d38dc986fe042b1e92785fb9d8df41f75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
